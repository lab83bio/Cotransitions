{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ccc63-6c12-4cf6-9921-f958ff2ae29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import json\n",
    "import tqdm\n",
    "import pickle\n",
    "import urllib\n",
    "import requests\n",
    "import textwrap\n",
    "import functools\n",
    "import traceback\n",
    "import itertools\n",
    "import matplotlib\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import plotly.express as px\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from pygosemsim import graph\n",
    "from pygosemsim import download\n",
    "from pygosemsim import term_set\n",
    "from pygosemsim import similarity\n",
    "\n",
    "from utilities.funcs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f861bde7-ddf6-429b-ae27-fa826d61684d",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2590e5d-4940-4c45-9b3b-01845677bcb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "goslim_subset = 'goslim_generic'\n",
    "level = 'at2759'\n",
    "odb_levels = 'https://v101.orthodb.org/download/odb10v1_levels.tab.gz'\n",
    "levels = pd.read_table(odb_levels, compression='gzip', header=None)\n",
    "levels[0] = levels[0].apply(lambda x: f'at{x}')\n",
    "levels = dict(levels[[0,1]].values.tolist())\n",
    "levelname = levels.get(level)\n",
    "goaspects = ('P','C','F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073d0aa4-7d79-418c-9c0d-ad41528d81e1",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a99ad-ecb0-4a06-9c3f-c9efa05b654b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INFILES\n",
    "\n",
    "transitions_file = 'Eukaryota.transitions.mini'\n",
    "clusters_raw_file = 'Eukaryota.clusters.mini'\n",
    "ogunigo_file = f'external/og_uni_go_{levelname}_experimental_mini.tsv'\n",
    "koog_file = 'external/ko_og_pathway.tsv'\n",
    "# #OUTFILES\n",
    "\n",
    "transitions_ogs_file = f'{transitions_file}.ogs'\n",
    "clusters_file = f'{clusters_raw_file}.grouped'\n",
    "allogs_file = f\"{transitions_file.split('.')[0]}.ogs\"\n",
    "ogunigotrans_file = f'{transitions_file}.unigo.experimental'\n",
    "pygosemsim_file = f'{ogunigotrans_file}.pygosemsim'\n",
    "\n",
    "goslim_subset = 'goslim_generic.obo'\n",
    "goobo_file = 'external/go.obo'\n",
    "goslim_file = 'external/annotations.generic'\n",
    "\n",
    "odbfile = 'external/odbinfos.pickle'\n",
    "\n",
    "# LINKS\n",
    "\n",
    "odb_og2genes = 'https://v101.orthodb.org/download/odb10v1_OG2genes.tab.gz'\n",
    "odb_genexrefs = 'https://v101.orthodb.org/download/odb10v1_gene_xrefs.tab.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb27c14-e827-4c2a-92e1-bf25c5d0a9cd",
   "metadata": {},
   "source": [
    "# Processing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d9ed8-b0a6-4011-84a3-03fb16231e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transition pairs to single, most significant ogs\n",
    "transitionstoogs(transitions_file).to_csv(transitions_ogs_file, sep='\\t', index=None)\n",
    "\n",
    "# processing raw clusters file --> dataframe\n",
    "clustersfromraw(clusters_raw_file, transitions_file).to_csv(clusters_file, sep='\\t', index=None)\n",
    "\n",
    "# all ogs list\n",
    "transitionsogs = transitionstoogs(transitions_file)\n",
    "allogsdf = transitionsogs[['og','ogname']]\n",
    "allogsdf.columns = ['og','name']\n",
    "\n",
    "allogsdf.to_csv(allogs_file, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f0d6e1-fff1-41e4-9302-1c1413b39bae",
   "metadata": {},
   "source": [
    "# GO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8fe5d0-0630-4f44-9ca2-901f517a3412",
   "metadata": {},
   "source": [
    "## GO Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c6b054-91a6-4751-a7c0-51b1f709bec7",
   "metadata": {},
   "source": [
    "Decomment the following cell for the long version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c828c-df74-43b5-ba7a-4b200706ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### for the long version\n",
    "# oguni_file = f'external/og_uni_{levelname}.tsv'\n",
    "# ogunigo_file = f'external/og_uni_go_{levelname}.tsv'\n",
    "\n",
    "# !wget external/http://release.geneontology.org/2020-01-01/annotations/goa_uniprot_all.gaf.gz\n",
    "# goa = 'external/goa_uniprot_all.gaf.gz'\n",
    "\n",
    "# xref = pd.read_table(odb_og2genes, compression='gzip', header=None)\n",
    "# og2genes = pd.read_table(ogb_genexrefs, compression='gzip', header=None)\n",
    "# og2genes = og2genes[og2genes[2]=='UniProt']\n",
    "# merged = pd.merge(og2genes, xref.rename(columns={0:3,1:0}))\n",
    "# merged2 = merged[merged[3].str.contains(level)]\n",
    "# merged2.columns = ['gene','id','db','og']\n",
    "# merged2.to_csv(oguni_file, sep='\\t', index=None)\n",
    "\n",
    "# !python3 utilities/oguni2chunk goa oguni_file ogunigo_file\n",
    "\n",
    "# oggo = pd.read_table(ogunigo_file)\n",
    "# ex = ['IDA', 'IMP', 'IPI', 'IEP', 'IGI']\n",
    "\n",
    "# oggo = oggo[oggo['og'].isin(set(oggo[oggo['evidence'].isin(ex)]['og']))]\n",
    "\n",
    "# oggo[~oggo['go'].isin(['GO:0008150', 'GO:0005575', 'GO:0003674'])\n",
    "#     ].to_csv(ogunigo_file.replace('.tsv', '_experimental.tsv'), \n",
    "#              sep ='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edaeb2f-df0a-493d-a667-6d4b2c551103",
   "metadata": {},
   "source": [
    "For the brief version (we'll attach these file in the folder 'external')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f0776-d528-48ce-ba98-e3a2c319f238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trans = pd.read_table(transitions_file)\n",
    "clu = pd.read_table(clusters_file)\n",
    "ogs = set(trans['Orthogroup1'].tolist()+trans['Orthogroup2'].tolist())\n",
    "\n",
    "# oguni = pd.read_table('../../og_uni_Eukaryota.tsv')\n",
    "# oguni[oguni['og'].isin(set(trans['Orthogroup1'].tolist()+trans['Orthogroup2'].tolist()))\n",
    "#      ].to_csv('external/og_uni_Eukaryota_mini.tsv', sep='\\t', index=None)\n",
    "\n",
    "# ogunigo = pd.read_table('../../og_uni_go_Eukaryota_experimental_filt.tsv')\n",
    "# ogunigo[ogunigo['og'].isin(ogs)\n",
    "#        ].to_csv(ogunigo_file, sep='\\t', index=None)\n",
    "\n",
    "transitions = pd.read_table(transitions_file)\n",
    "oggo = pd.read_table(ogunigo_file)\n",
    "oggo = oggo[oggo['og'].isin(set(transitions['Orthogroup1'].tolist()+\n",
    "                                transitions['Orthogroup2'].tolist()))]\n",
    "oggo.to_csv(ogunigotrans_file, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e602a0-b2e9-4891-8f75-5414df84e7f6",
   "metadata": {},
   "source": [
    "## PyGOSemSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4d726-89e1-456b-aa2b-3168c74137f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    download.obo(\"go-basic\")\n",
    "    download.download(\"goslim_chembl.obo\",\n",
    "        \"http://www.geneontology.org/ontology/subsets/goslim_chembl.obo\")\n",
    "    G = graph.from_resource(\"go-basic\")\n",
    "    G_chembl = graph.from_resource(\"goslim_chembl\")\n",
    "    similarity.precalc_lower_bounds(G)\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "def calcsim(indexgo1go2):\n",
    "    try:\n",
    "        sf = functools.partial(term_set.sim_func, \n",
    "                               G, similarity.resnik)\n",
    "        si = term_set.sim_bma(indexgo1go2[1], \n",
    "                              indexgo1go2[2], sf)\n",
    "    except:\n",
    "        si = 0\n",
    "    return [indexgo1go2[0], si]\n",
    "\n",
    "transitions = pd.read_table(transitions_file)\n",
    "oggo_df = pd.read_table(ogunigotrans_file)\n",
    "oggo = dict(oggo_df.groupby('og')['go'].apply(\n",
    "    lambda x: list(set(x))).reset_index().values)\n",
    "oggo_bp = dict(oggo_df[oggo_df['type']=='P'].groupby('og')[\n",
    "    'go'].apply(lambda x: list(set(x))).reset_index().values)\n",
    "oggo_cc = dict(oggo_df[oggo_df['type']=='C'].groupby('og')[\n",
    "    'go'].apply(lambda x: list(set(x))).reset_index().values)\n",
    "oggo_mf = dict(oggo_df[oggo_df['type']=='F'].groupby('og')[\n",
    "    'go'].apply(lambda x: list(set(x))).reset_index().values)\n",
    "dfs = []\n",
    "for OGGO, typ in zip([oggo_bp, oggo_cc, oggo_mf],\n",
    "                     ['BP', 'CC', 'MF']):\n",
    "    oggo_df = transitions[['Orthogroup1','Orthogroup2']].applymap(\n",
    "        lambda x: OGGO.get(x)).reset_index()\n",
    "    oggo_df.columns = ['index','go1', 'go2']\n",
    "    oggo_df = oggo_df.dropna()\n",
    "    simscore = Pool(500).map(calcsim, oggo_df.values.tolist())\n",
    "    simscore = dict(simscore)\n",
    "    oggo_df['simscore'] = oggo_df['index'].apply(\n",
    "        lambda x: simscore.get(x))\n",
    "    oggo_df = oggo_df.drop('index', axis=1)\n",
    "    oggo_df = oggo_df.reset_index(drop=True).rename(\n",
    "        columns={'simscore':f'{typ.lower()}sim', \n",
    "                 'go1':f'go1_{typ.lower()}', \n",
    "                 'go2':f'go2_{typ.lower()}'})\n",
    "    oggo_df[f'len_go1_{typ.lower()}'] = oggo_df[\n",
    "        f'go1_{typ.lower()}'].apply(len)\n",
    "    oggo_df[f'len_go2_{typ.lower()}'] = oggo_df[\n",
    "        f'go2_{typ.lower()}'].apply(len)\n",
    "    dfs.append(pd.concat([transitions.loc[\n",
    "        list(simscore.keys())].reset_index(drop=True), \n",
    "                          oggo_df], axis=1))\n",
    "total = (dfs[0]\n",
    " .merge(dfs[1], how='outer')\n",
    " .merge(dfs[2], how='outer')\n",
    ")\n",
    "total.to_csv(pygosemsim_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172834c-3f2f-4c2c-b90c-e1d379e0e166",
   "metadata": {},
   "source": [
    "### Figure 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee58984-3ab1-4d15-a640-d4ab1226ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "title = 'GO experimental similarity vs p-value'\n",
    "\n",
    "df = pd.read_table(pygosemsim_file)\n",
    "\n",
    "ths = list(reversed(list(map(lambda x: 10**(-x/100), \n",
    "                             range(0,2000,100)))[3:]))[:-1]\n",
    "chunks, ts = [],[]\n",
    "for n, t in   enumerate(ths):\n",
    "    if n == 0:\n",
    "        chunk = df[df['p']<=t]\n",
    "    if n == len(ths)-1:\n",
    "        chunk = df[df['p']>t]\n",
    "    else:\n",
    "        try:\n",
    "            chunk = df[df['p'].between(t, ths[n+1], \n",
    "                                       inclusive='left')]\n",
    "        except:\n",
    "            pass\n",
    "    chunks.append(chunk)\n",
    "    ts.append(\"{:.0e}\".format(t))\n",
    "    \n",
    "columns = df.columns[df.columns.str.contains('sim')]\n",
    "lens = list(map(lambda x: len(x), chunks))*len(columns)\n",
    "scatter, line = [], []\n",
    "for column in columns:\n",
    "    name = column.rstrip('sim').upper()\n",
    "    c = 100\n",
    "    df1 = df[(df[f\"len_go1_{column}\".replace('sim', '')]>n)&\n",
    "             (df[f\"len_go2_{column}\".replace('sim', '')]>n)]\n",
    "    ser = pd.Series([len(d[d[column]>=df1[column].mean()])/len(d) \n",
    "                     if len(d) != 0 else 0 \n",
    "                     for d in chunks]).reset_index()\n",
    "    ser['type'] = name\n",
    "    ser['slices'] = ts\n",
    "    scatter.append(ser)\n",
    "    \n",
    "lab = 'Fraction > mean score'\n",
    "data = pd.concat(scatter).reset_index(drop=True)\n",
    "data = data.rename(columns={0: lab})\n",
    "data['slices'] = data['slices'].astype(str)\n",
    "data['lengths'] = lens\n",
    "data.columns = ['Index','Fraction > mean score', \n",
    "                'GO class', 'Slice', 'Numerosity']\n",
    "data['Log(N)'] = data['Numerosity'].apply(lambda x: np.log10(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c708f-41f6-48a8-9c0b-f2a0cf3c0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "\n",
    "factor = 3.1/4\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 0.8\n",
    "plt.rcParams['lines.linewidth'] = 0.8\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['xtick.labelsize'] = 6\n",
    "plt.rcParams['ytick.labelsize'] = 6\n",
    "plt.rcParams['legend.fontsize'] = 6\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.1, 3.1), dpi=100) \n",
    "\n",
    "for typ, col, zo in zip(['CC','BP','MF'],[(0.75,0.75,0),\n",
    "                                          (0,0.75,0.75),\n",
    "                                          (0.75,0,0.75)],\n",
    "                        [1,2,3]):\n",
    "\n",
    "    plt.plot(data[data['GO class']==typ]['Slice'], \n",
    "             data[data['GO class']==typ][lab], \n",
    "             label=typ, color=col, zorder=zo)\n",
    "    plt.scatter(data[data['GO class']==typ]['Slice'], \n",
    "                data[data['GO class']==typ][lab], \n",
    "                label=typ, color=col, linewidths=0,\n",
    "                sizes=[i*factor*i*factor*math.pi \n",
    "                       for i in data[data['GO class']==typ\n",
    "                                    ]['Log(N)']], zorder=zo)\n",
    "\n",
    "\n",
    "scatter = plt.scatter([0,1,2], [0,1,2], color=(1,1,1),\n",
    "                  sizes=[x*factor*x*factor*math.pi \n",
    "                         for x in (2,3,4)], zorder=0)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "hl = sorted(zip(handles, labels), key=operator.itemgetter(1))\n",
    "hl = [hl[0],hl[2],hl[4]]\n",
    "handles2, labels2 = zip(*hl)\n",
    "legend3 = ax.legend(handles2, labels2, loc=(0.7,0.75), \n",
    "                    title='GO aspect', frameon=False)\n",
    "\n",
    "handles, labels = scatter.legend_elements(\n",
    "    prop=\"sizes\", alpha=0.2, markeredgewidth=0)\n",
    "labels = [2,3,4]\n",
    "legend2 = ax.legend(handles, labels, loc=(0.73,0.5), \n",
    "                    title=\"Log(N)\", frameon=False)\n",
    "plt.gca().add_artist(legend3)\n",
    "\n",
    "plt.xticks(rotation=-45, ha=\"left\", rotation_mode=\"anchor\")\n",
    "ax.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "plt.xlabel(\"p-value (slice)\")\n",
    "plt.ylabel(\"$N_{score>mean}$ / N\")\n",
    "\n",
    "ax.set_xticklabels(labels=[\"$10^{-tag}$\".replace(\n",
    "    'tag', str(s).split('-')[1]) for s in \n",
    "                           data[data['GO class']==typ]['Slice']])\n",
    "\n",
    "plt.ylim(0,1)\n",
    "\n",
    "save = True\n",
    "if save == True:\n",
    "    fig.tight_layout()\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(f'images/{pygosemsim_file}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0d94a-5ee4-4bd9-8e95-c3376177e3da",
   "metadata": {},
   "source": [
    "## GO SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e2f2c-03b0-47c9-8f22-2bcd7762b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://purl.obolibrary.org/obo/go.obo -P external/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820dc88-3fb7-487b-b8a4-cdd4d789a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/owlcollab/owltools/releases/download/2020-04-06/owltools -P utilities/\n",
    "!chmod +x utilities/owltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dbb2e0-2239-4270-aae7-7881774a60ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve all GOs available from go.obo file\n",
    "mini, minimini = [], []\n",
    "for line in open(goobo_file).readlines()[29:]:\n",
    "    if line.startswith('id: GO'):\n",
    "        mini.append(minimini)\n",
    "        minimini = []\n",
    "    minimini.append(line)\n",
    "gos = pd.DataFrame([[m[0].strip().split('id: ')[1],\n",
    "                     m[1].strip().split('name: ')[1],\n",
    "                     m[2].strip().split('namespace: ')[1]] \n",
    "                    for m in mini[1:]]).drop_duplicates(0)\n",
    "gos = gos[~gos[1].str.contains('obsolete')]\n",
    "gos = gos.reset_index(drop=True).reset_index()\n",
    "gos.columns = ['index','go','goname','gotype']\n",
    "gos['gotype'] = gos['gotype'].apply(lambda x: \n",
    "                                    'P' if 'biological' in x else \n",
    "                                    'F' if 'molecular' in x else \n",
    "                                    'C' if 'component' in x else None)\n",
    "gonames = dict(gos[['go','goname']].values)\n",
    "gotypes = dict(gos[['go','gotype']].values)\n",
    "\n",
    "# GO to GO slim using OWLTOOLS (https://github.com/owlcollab/owltools)\n",
    "def gostoslim(goobo, outfile, subset, gos):\n",
    "\n",
    "    print('!gaf-version: 2.0', file=open(outfile, 'w'))\n",
    "    for row in gos.values.tolist():\n",
    "        a = list(map(str, [' ']*16))\n",
    "        a[1], a[4] = str(row[0]), row[1]\n",
    "        print('\\t'.join(a), file=open(outfile, 'a'))\n",
    "    \n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        !utilities/owltools {goobo} --gaf {outfile} --map2slim --subset {subset} --write-gaf {outfile}.gaf\n",
    "    \n",
    "    slim = pd.read_table(outfile+'.gaf', comment='!', header=None)\n",
    "    slim = slim[[1,4]]\n",
    "    slim.columns = ['index','go']\n",
    "    slim['index'] = slim['index'].apply(lambda x: int(x[1:]))\n",
    "    \n",
    "    return slim\n",
    "\n",
    "slim = gostoslim(goobo_file, goslim_file, \n",
    "                 os.path.basename(goslim_subset.replace('.obo', '')\n",
    "                            ), gos).assign(db=goslim_subset)\n",
    "\n",
    "# re-mapping any missing goslim_generic GO to goslim_PIR (more specific)\n",
    "if 'generic' in goslim_subset:    \n",
    "    missing = pd.merge(gos.rename(columns={0:'go'}), \n",
    "                       slim.rename(columns={'go':'goslim'}),how='outer')\n",
    "    missing = missing[missing['goslim'].isna()][['index','go']]\n",
    "    \n",
    "    slim_pir = gostoslim(goobo_file, goslim_file.replace('.generic', '.pir'), \n",
    "                      os.path.basename(goslim_subset.replace(\n",
    "                          '_generic.obo', '_pir')), missing\n",
    "                     ).assign(db=goslim_subset.replace(\n",
    "        '_generic.obo', '_pir'))\n",
    "    final = pd.merge(gos, pd.concat(\n",
    "        [slim, slim_pir]).rename(\n",
    "        columns={'go':'goslim'}),on='index',how='outer').dropna()\n",
    "    final['goslimname'] = final['goslim'].apply(lambda x: gonames.get(x))\n",
    "    final['goslimtype'] = final['goslim'].apply(lambda x: gotypes.get(x))\n",
    "    slim = final\n",
    "\n",
    "slim = slim[['go','gotype','goname','goslim','goslimtype','goslimname','db']]\n",
    "slim.to_csv(f'{goslim_file}.tsv', index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf6d1b-4614-4863-a2ed-022fe3f474bb",
   "metadata": {},
   "source": [
    "### Orthogroups GO slim mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860a7fb-997f-4227-9ea6-ea9be1c1641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ogunigo = pd.read_table(ogunigo_file)\n",
    "slim = pd.read_table(f'{goslim_file}.tsv')\n",
    "\n",
    "ogunigoslim = pd.merge(ogunigo, slim, how='outer'\n",
    "                      ).dropna().drop_duplicates()\n",
    "ogunigoslim.to_csv(f'{ogunigotrans_file}.slim', \n",
    "                   sep='\\t', index=None)\n",
    "\n",
    "transitionsogs = transitionstoogs(transitions_file)\n",
    "goslim = pd.read_table(f'{ogunigotrans_file}.slim')\n",
    "\n",
    "singlego = pd.merge(transitionsogs, goslim, on='og')\n",
    "singlego = singlego.drop_duplicates([\n",
    "    'og','goname','goslimname'])\n",
    "\n",
    "# exclude macro GO classes\n",
    "singlego = singlego[~singlego['goslimname'].isin(\n",
    "    ['biological_process','cellular_component',\n",
    "     'molecular_function'])]\n",
    "\n",
    "# transitions pvalue to -log10 pvalue\n",
    "singlego['log10pval'] = singlego['pval'].apply(\n",
    "    lambda x: -np.log10(x))\n",
    "singlego['log10adjpval'] = singlego['adjpval'].apply(\n",
    "    lambda x: -np.log10(x))\n",
    "final = singlego.reset_index(drop=True).sort_values(\n",
    "    'log10pval', ascending=False)\n",
    "\n",
    "# using scalepval function to force pvalues in a \n",
    "# user defined range (-6:-2, 2:6; >6 == 6)\n",
    "final2 = scalepval(final, 'log10pval', 2, None)\n",
    "\n",
    "final2.to_csv(str(f'{ogunigotrans_file}.slim'\n",
    "                 ).replace('transitions','ogs'), \n",
    "              sep='\\t', index=None)\n",
    "\n",
    "#-log10 pvalues distribution after scaling them\n",
    "final2['log10pvalscaled'].plot.hist(\n",
    "    bins=100, figsize=(3.1, 3.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f3195e-b0b8-4e3d-bcfc-76427f2d11f7",
   "metadata": {},
   "source": [
    "### Orthogroup ranking files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8c711-2792-4108-9b40-e1a8f81d3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a pval based ranking file containing orthogroups and their GO annotations\n",
    "for goclass in goaspects:\n",
    "    finalfilt = final2[final2['goslimtype']==goclass]\n",
    "    finalfilt = finalfilt[['og','log10pvalscaled',\n",
    "                           'goslim','goslimname',\n",
    "                           'ogname']]\n",
    "    finalfilt.columns = ['name','score','feature',\n",
    "                         'description','extraname']\n",
    "    finalfilt.drop_duplicates(['name','feature',\n",
    "                               'description']\n",
    "        ).to_csv(f\"{f'{ogunigotrans_file}.slim'.replace('transitions','ogs')}.{goclass}.ranking\", \n",
    "                 sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0cbbe-ae7e-467e-8117-59f5e6d0a10a",
   "metadata": {},
   "source": [
    "### GO Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb3c7ab-a1a5-4066-b37a-99116635ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrichemnt analysis using clusterProfiler library in R (https://github.com/YuLab-SMU/clusterProfiler)\n",
    "for goclass in goaspects:\n",
    "    file = f\"{f'{ogunigotrans_file}.slim'.replace('transitions','ogs')}.{goclass}.ranking\"\n",
    "    !utilities/enrich.R --input_file {file} --pval_cutoff 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98668802-6d7c-4197-8c3b-e10c52e97e26",
   "metadata": {},
   "source": [
    "### Figure 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac81f3-6532-44ed-892b-6c2236158994",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorsfrommap = [plt.cm.jet(n)[0:3] for n in np.array(list(range(0,12)))/11]\n",
    "\n",
    "newcolors = np.array([(0.75,0.75,0,i/255) for i in range(255)])\n",
    "newcmp1 = matplotlib.colors.ListedColormap(newcolors)\n",
    "newcolors = np.array([(0,0.75,0.75,i/255) for i in range(255)])\n",
    "newcmp2 = matplotlib.colors.ListedColormap(newcolors)\n",
    "newcolors = np.array([(0.75,0,0.75,i/575) for i in range(255)])\n",
    "newcmp3 = matplotlib.colors.ListedColormap(newcolors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc4786-2ee3-4ca4-801c-e1476b9a643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = 0.05\n",
    "maxgr = 30\n",
    "save = True\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 0.8\n",
    "plt.rcParams['lines.linewidth'] = 0.8\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['xtick.labelsize'] = 6\n",
    "plt.rcParams['ytick.labelsize'] = 6\n",
    "plt.rcParams['legend.fontsize'] = 6\n",
    "\n",
    "def plotenrichment(enrfile, rankfile, colormap, title, \n",
    "                   pvalthreshold, genesizelimit, save=False):\n",
    "    \n",
    "    def customwrap(s, width=20):\n",
    "        return \"\\n\".join(textwrap.wrap(s,width=width))\n",
    "\n",
    "    df = pd.read_table(enrfile, sep=',').drop(\n",
    "        'Unnamed: 0', axis=1).dropna()\n",
    "\n",
    "    df = df[df['pvalue']<=pvalthreshold]\n",
    "    df = df.sort_values('NES', ascending=False)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    df['Description'] = df['Description'].apply(\n",
    "        lambda x: 'nucleobase-cont. small mol. met. proc.' if 'nucleobase-containing small molecule metabolic process' in x \n",
    "        else 'gen. of precursor metabol. and energy' if 'generation of precursor metabolites and energy' in x\n",
    "        else x)\n",
    "\n",
    "    df['Description'] = df['Description'].apply(lambda x: customwrap(x))\n",
    "\n",
    "    df['core_enrichment'] = df['core_enrichment'].apply(lambda x: x.split('/'))\n",
    "    ognames = dict(pd.read_table(rankfile).drop_duplicates(\n",
    "        'name')[['name','extraname']].values)\n",
    "    df['core_enrichment_names'] = df['core_enrichment'].apply(\n",
    "        lambda x: [ognames.get(i) for i in x])\n",
    "    df['coreSize'] = df['core_enrichment'].apply(len)\n",
    "    df['coreSizenorm'] = df['coreSize'].apply(\n",
    "        lambda x: genesizelimit if x>=genesizelimit else x)\n",
    "\n",
    "    fig, (cax,ax) = plt.subplots(ncols=2, figsize=(4,4), dpi=100, \n",
    "                                 gridspec_kw={'width_ratios':[0.05, 1]})\n",
    "\n",
    "    x = df['Description'].values\n",
    "    ##########\n",
    "    # x = df['Description'].values.tolist()+[' ','  ','   ']\n",
    "    ##########\n",
    "    x = np.array(['nucleob.-containing small mol. metabolic process' \n",
    "                  if 'nucleobase-containing small molecule metabolic process' \n",
    "                  in i else i for i in x])\n",
    "    y = df['NES'].values\n",
    "    ##########\n",
    "    # y = df['NES'].values.tolist()+[0,0,0]\n",
    "    ##########\n",
    "    c = df['coreSizenorm'].values\n",
    "\n",
    "    colmap = colormap\n",
    "    colors1 = colmap(c/c.max())\n",
    "    sm = plt.cm.ScalarMappable(cmap=colmap, \n",
    "                               norm=plt.Normalize(vmin=c.min(), vmax=c.max()))\n",
    "\n",
    "    cbar = plt.colorbar(sm, cax)\n",
    "    cbar.set_ticks(list(range(0,genesizelimit+1,int(genesizelimit/5))))\n",
    "    cbar.set_ticklabels(list(range(\n",
    "        0,genesizelimit,int(genesizelimit/5)))+[f'>{genesizelimit}'])\n",
    "    cbar.outline.set_linewidth(0.8)\n",
    "    cbar.set_label('core enrichment', loc='top', fontsize=6)\n",
    "\n",
    "    ax.barh(x, y, color=colors1, edgecolor = colormap.colors[-1])\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.tick_params(axis='both', which='major')\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines[['right','bottom']]\n",
    "    ax.set_xlim(-4, 4)\n",
    "    ax.set_xlabel('NES')\n",
    "\n",
    "    cax.yaxis.tick_left()\n",
    "    cax.tick_params(axis='both', which='major')\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save == True:\n",
    "        fig.savefig(f'images/{enrfile}.pdf')\n",
    "\n",
    "for goclass in ['P','C','F']:\n",
    "    rankfile = f\"{f'{ogunigotrans_file}.slim'.replace('transitions','ogs')}.{goclass}.ranking\"\n",
    "    enrfile = f\"{rankfile}.enriched\"\n",
    "    plotenrichment(enrfile, rankfile, newcmp1 if goclass == 'C' \n",
    "                   else newcmp2 if goclass == 'P' else newcmp3, \n",
    "                   'NES BP' if goclass == 'P' else 'NES CC' \n",
    "                   if goclass == 'C' else 'NES MF', pval, maxgr, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850e4c8-ee01-4eae-b6de-dbad40752d3e",
   "metadata": {},
   "source": [
    "# KEGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690d08a-9c7a-46df-8494-46bf66bbdb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download per each orthogroup all available databases annotations from orthodb\n",
    "!python3 utilities/oginfo.py -i {allogs_file} -o {odbfile} -p 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb67ff1-499c-43d9-8676-880fd00b57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "odbinfos = dict(pickle.load(open(odbfile, 'rb')))\n",
    "\n",
    "# and store them in a dataframe\n",
    "dfs = []\n",
    "for o in odbinfos.keys():\n",
    "    data = odbinfos.get(o)\n",
    "    if len(data)>0:\n",
    "        data = data['data']\n",
    "        keys = [k for k in data.keys() if type(data.get(k)) == list]\n",
    "        if len(keys)>0:\n",
    "            dfs.append(pd.concat([pd.json_normalize(data.get(k)).assign(db=k) \n",
    "                            for k in keys]).assign(og=o))\n",
    "\n",
    "dfs = pd.concat(dfs).drop(['name','type','count'], \n",
    "                          axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce1b0b5-2093-4ee5-8f2d-851a2fe4a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.read_table(clusters_file)\n",
    "\n",
    "# add orthodb annotations to each transitions\n",
    "transitionsogs = transitionstoogs(transitions_file)\n",
    "odbtransitions = pd.merge(dfs, transitionsogs, on='og')[['description','id','db','og','ogname']]\n",
    "\n",
    "odbtransitions = pd.merge(odbtransitions, clusters[['og','cluster']], on='og', how='outer')\n",
    "odbtransitions.to_csv(f'{transitions_file}.odb', sep='\\t', index=None)\n",
    "\n",
    "# same to each clusters\n",
    "odbclusters = pd.merge(dfs, clusters[['cluster','n','og','name']])[['description','id','db','og','name','cluster','n']]\n",
    "odbclusters.to_csv(f'{clusters_file}.odb', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04974417-b64c-4384-99cc-3d27b177aa2a",
   "metadata": {},
   "source": [
    "## Enrich KEGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e02c4b-50c4-412a-9a21-4166fba9fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_file = f'{transitions_file}.odb' # columns = description, id, db, og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c4481-d406-44ad-8105-b543c42c3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitionsogs = transitionstoogs(transitions_file)\n",
    "\n",
    "# filter kegg ids (e.g. metabolism)\n",
    "filton = '00'\n",
    "# filter out KEGG macro classes\n",
    "filterkegg = ['Metabolic pathways']\n",
    "\n",
    "kegg = pd.read_table(kegg_file)\n",
    "kegg = kegg.drop_duplicates(['og','id'])\n",
    "kegg = kegg[(kegg['db'].str.contains('KEGG'))&~(kegg['description'].isin(filterkegg))]\n",
    "kegg = kegg[kegg['id'].apply(lambda x: re.split('(\\d+)', x)[1]).str.startswith(filton)] if filton else kegg\n",
    "\n",
    "transitionsogskegg = pd.merge(transitionsogs, kegg, on=['og','ogname'])\n",
    "transitionsogskegg['log10pval'] = transitionsogskegg['pval'].apply(lambda x: -np.log10(x))\n",
    "transitionsogskegg['log10adjpval'] = transitionsogskegg['adjpval'].apply(lambda x: -np.log10(x))\n",
    "transitionsogskegg = transitionsogskegg.reset_index(drop=True).sort_values('log10pval', ascending=False)\n",
    "\n",
    "# -log10 pval scaling\n",
    "transitionsogskegg = scalepval(transitionsogskegg, 'log10pval', 2, None)\n",
    "\n",
    "transitionsogskegg.to_csv(f'{kegg_file}.kegg', sep='\\t', index=None)\n",
    "\n",
    "transitionsogskegg['log10pvalscaled'].plot.hist(bins=100, figsize=(3.1,3.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf431b-1f81-4197-8685-999d62b85ea8",
   "metadata": {},
   "source": [
    "### KEGG ranking file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ab5a1-32c8-4082-8fd7-42b115a12e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitionsogskeggfilt = transitionsogskegg[['og','log10pvalscaled','id','description','ogname']]\n",
    "transitionsogskeggfilt.columns = ['name','score','feature','description','extraname']\n",
    "\n",
    "transitionsogskeggfilt.to_csv(f'{kegg_file}.kegg.ranking', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69476ddb-4178-4f19-803d-04f57c08735e",
   "metadata": {},
   "source": [
    "### KEGG Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99818b1b-fdec-4e9e-be03-a484e3db8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f'{kegg_file}.kegg.ranking'\n",
    "!utilities/enrich.R --input_file {file} --pval_cutoff 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0cbeed-9228-4b5b-91a5-88169e9d7174",
   "metadata": {},
   "source": [
    "### Figure 2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436af09-5c31-416a-a87c-e1f7d6cc8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorsfrommap = [plt.cm.jet(n)[0:3] for n in np.array(list(range(0,12)))/11]\n",
    "\n",
    "viridis = plt.cm.get_cmap('viridis', 256)\n",
    "newcolors = np.array([(1,0.7,0.4,i/255) for i in range(255)])\n",
    "newcmp3 = matplotlib.colors.ListedColormap(newcolors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3953ee8c-0262-4aeb-97bf-ac2819109245",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrfile = f'{file}.enriched'\n",
    "pval = 0.05\n",
    "maxgr = 6\n",
    "save = True\n",
    "\n",
    "plotenrichment(enrfile, file, newcmp3,  f'NES KEGG Meta', pval, maxgr, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ae2a0c-f877-4b55-8e69-3fbd28a21296",
   "metadata": {},
   "source": [
    "# Clusters analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dddb9d2-a747-43b9-a28b-2956eb4d1307",
   "metadata": {},
   "source": [
    "## Clusters scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d6544-0f1a-4ef9-aa4d-1297a420736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = description, id, db, og\n",
    "kegg_file = f'{clusters_file}.odb'\n",
    "\n",
    "goslim_file = f'{ogunigotrans_file}.slim'.replace('transitions','ogs')\n",
    "\n",
    "# filter kegg ids (e.g. metabolism)\n",
    "filton = '00'\n",
    "# filter out kegg macro classes\n",
    "filterkegg = ['Metabolic pathways']\n",
    "# filter out go macro classes\n",
    "filtergo = ['biological process','molecular function','cellular component', 'protein binding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06848887-6263-4908-b1aa-2aad02aaa318",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.read_table(clusters_file)\n",
    "\n",
    "kegg = pd.read_table(kegg_file)\n",
    "kegg = kegg.drop_duplicates(['og','id'])\n",
    "kegg = kegg[(kegg['db'].str.contains('KEGG'))]\n",
    "kegg = kegg[~(kegg['description'].isin(filterkegg))]\n",
    "\n",
    "keggmeta = kegg[kegg['id'].apply(lambda x: re.split('(\\d+)', x)[1]).str.startswith(filton)]\n",
    "\n",
    "goslim = pd.read_table(goslim_file)\n",
    "goslim = goslim[~goslim['goslimname'].isin(filtergo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f195bb-f034-48c4-a906-6d064157df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupfeatures(df, tag):\n",
    "    ''' for each user defined feature, calculates for each cluster the percentage of most frequent ones '''\n",
    "\n",
    "    dfs = []\n",
    "    for c in set(df['cluster']):\n",
    "\n",
    "        dfc = df[df['cluster']==c].drop_duplicates()\n",
    "\n",
    "        dfes, dnas = [], []\n",
    "        for f in set(dfc['feature']):\n",
    "            dfe = dfc[dfc['feature']==f]\n",
    "            dfes.append((dfe.iloc[0]['feature'], len(dfe)))\n",
    "            dnas.append((dfe.iloc[0]['featurename'], len(dfe)))\n",
    "\n",
    "        dfcfeat = pd.DataFrame(dfes, columns = ['feature', 'og'])\n",
    "        dfcnames = pd.DataFrame(dnas, columns = ['featurename', 'og'])\n",
    "\n",
    "        features = ' --- '.join(dfcnames.sort_values('og', ascending=False)['featurename'].values)\n",
    "        frequencies = ' --- '.join(map(str, dfcnames.sort_values('og', ascending=False)['og'].values))\n",
    "        annotatedogs = len(list(set(dfc['og'])))\n",
    "        population = dfc['n'].iloc[0]\n",
    "        frequency = dfcfeat.max()['og']\n",
    "        mostfreqfeat = ' --- '.join(dfcfeat[dfcfeat['og']==frequency]['feature'].tolist())\n",
    "        mostfreqname = ' --- '.join(dfcnames[dfcnames['og']==frequency]['featurename'].tolist())\n",
    "        \n",
    "        # at least 2 og annotated\n",
    "        score = round(frequency/annotatedogs, 2) if not annotatedogs <= 1 else 0\n",
    "\n",
    "        dfs.append([c, population, tag, annotatedogs, frequency, score, \n",
    "                    mostfreqname, mostfreqfeat, features, frequencies])\n",
    "\n",
    "    columns = ['cluster','pop','db','pop.ann','n.mostfreq','score',\n",
    "               'mostfreq','mostfreqfeat','allfeat','n.allfeat']\n",
    "    \n",
    "    return pd.DataFrame(dfs, columns = columns)\n",
    "\n",
    "# standardize datasets header\n",
    "go = goslim[['og','ogname','goslim','goslimname','goslimtype']]\n",
    "go.columns = ['og','ogname','feature','featurename','type']\n",
    "\n",
    "ognames = dict(clusters[['og','name']].values)\n",
    "\n",
    "# all keggs available\n",
    "kegg['ogname'] = kegg['og'].apply(lambda x: ognames.get(x))\n",
    "kegg = kegg[['og','ogname','id','description']].assign(type='K')\n",
    "kegg.columns = ['og','ogname','feature','featurename','type']\n",
    "\n",
    "# only metabolism associated kegg \n",
    "keggmeta['ogname'] = keggmeta['og'].apply(lambda x: ognames.get(x))\n",
    "keggmeta = keggmeta[['og','ogname','id','description']].assign(type='Km')\n",
    "keggmeta.columns = ['og','ogname','feature','featurename','type']\n",
    "\n",
    "dfK = groupfeatures(pd.merge(clusters, kegg, on='og'), 'K')\n",
    "dfKm = groupfeatures(pd.merge(clusters, keggmeta, on='og'), 'Km')\n",
    "dfP = groupfeatures(pd.merge(clusters, go[go['type']=='P'], on='og'), 'P')\n",
    "dfF = groupfeatures(pd.merge(clusters, go[go['type']=='F'], on='og'), 'F')\n",
    "dfC = groupfeatures(pd.merge(clusters, go[go['type']=='C'], on='og'), 'C')\n",
    "# string = pd.read_table(f'{string_outfile}.networkx')\n",
    "\n",
    "# final = pd.concat([dfK,dfKm,dfP,dfF,dfC,string]).sort_values(\n",
    "final = pd.concat([dfK,dfKm,dfP,dfF,dfC]).sort_values(\n",
    "    ['cluster','db'], ascending=[True,False])\n",
    "final['score'] = [x[1] if x[0] >1 else 0\n",
    "                  for x in final[['n.mostfreq','score']\n",
    "                                ].values.tolist()]\n",
    "\n",
    "clusters = clusters.dropna(subset=['cluster','n','og','name'])\n",
    "cluog = dict(clusters.groupby('cluster')['og'].apply(list).apply(lambda x: ' --- '.join(x)).reset_index().values)\n",
    "cluna = dict(clusters.groupby('cluster')['name'].apply(list).apply(lambda x: ' --- '.join(x)).reset_index().values)\n",
    "final['ogs'] = final['cluster'].apply(lambda x: cluog.get(x))\n",
    "final['ognames'] = final['cluster'].apply(lambda x: cluna.get(x))\n",
    "\n",
    "final.to_csv(f'{clusters_file}.scores', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e9c30-9e1d-474a-a4ac-bae04b5f34a5",
   "metadata": {},
   "source": [
    "### Supplementary figure 7g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06c492-1cc7-4ae0-9c29-3c069eba1a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([dfK,dfKm,dfP,dfF,dfC]).sort_values(\n",
    "    ['cluster','db'], ascending=[True,False])\n",
    "final['annscore'] = final['pop.ann']/final['pop']\n",
    "final['annscore'] = final['annscore'].apply(lambda x: round(x, 2))\n",
    "final = final.reset_index(drop=True)\n",
    "\n",
    "maxn = 5\n",
    "final['pop'] = final['pop'].apply(lambda x: maxn if x >= maxn else x)\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 0.8\n",
    "plt.rcParams['lines.linewidth'] = 0.8\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['xtick.labelsize'] = 6\n",
    "plt.rcParams['ytick.labelsize'] = 6\n",
    "plt.rcParams['legend.fontsize'] = 6\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    1,len(set(final['pop'])),\n",
    "    figsize=(len(set(final['pop']))*1, 3.1), \n",
    "    dpi=100, sharey=True)\n",
    "\n",
    "for i, ax in zip(set(final['pop']), axes):\n",
    "    for db, col in zip(['P','C','F','K','Km'], \n",
    "                       [(0,0.75,0.75),(0.75,0.75,0),\n",
    "                        (0.75,0,0.75),(1,0.5,0.5),\n",
    "                        (1,0.7,0.4)]):\n",
    "        \n",
    "        d = final[final['db']==db][final['pop']==i]\n",
    "        d[db] = d['annscore']\n",
    "        d.sort_values(db)[db].plot.kde(color=col, ax=ax)\n",
    "    \n",
    "    ax.spines[['top','right','left']].set_visible(False)\n",
    "    ax.set_xticks([0, 0.5, 1])\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.tick_params(axis='y', which='both', left=False)\n",
    "    \n",
    "    ax.set_xlabel(i)\n",
    "    if i == maxn:\n",
    "        ax.set_xlabel('â‰¥'+str(i))\n",
    "\n",
    "axes[0].spines[['left']].set_visible(True)\n",
    "axes[-1].spines[['bottom']].set_visible(True)\n",
    "plt.ylim(0,3.5)\n",
    "plt.xlim(0,1)\n",
    "\n",
    "plt.legend(['BP','CC','MF','KEGG','KEGG_Meta'], \n",
    "           loc=(-0.2, 0.7), frameon=False, title='Database')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'images/{clusters_file}_annotationscore_multi.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01ae7e-8e1d-47a6-a054-21320fa65957",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([dfK,dfKm,dfP,dfF,dfC]).sort_values(\n",
    "    ['cluster','db'], ascending=[True,False])\n",
    "final['annscore'] = final['pop.ann']/final['pop']\n",
    "final['annscore'] = final['annscore'].apply(lambda x: round(x, 2))\n",
    "final = final.reset_index(drop=True)\n",
    "fig, axes = plt.subplots(1,1,figsize=(3.1,3.1), dpi=150, sharex=True)\n",
    "\n",
    "for db, col in zip(['P','C','F','K','Km'], [(0,0.75,0.75),(0.75,0.75,0),(0.75,0,0.75),(1,0.5,0.5),(1,0.7,0.4)]):\n",
    "\n",
    "    d = final[final['db']==db]\n",
    "    d[db] = d['annscore']\n",
    "    d.sort_values(db)[db].plot.kde(color=col, ax=axes)\n",
    "axes.spines[['right','top']].set_visible(False)\n",
    "plt.legend(['BP','CC','MF','KEGG','KEGG_Meta'], loc='upper left', frameon=False, title='Database')\n",
    "fig.tight_layout()\n",
    "plt.ylim(0,3)\n",
    "plt.xlim(0,1)\n",
    "fig.savefig(f'images/{clusters_file}_annotationscore_single.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd2bbe-070c-4b71-ad8e-091301bc4c1e",
   "metadata": {},
   "source": [
    "## Supplementary figure 7h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43a62d5-18e5-45aa-a944-e1e9bd07f2ca",
   "metadata": {},
   "source": [
    "Uncomment the cell below to generate `external/ko_og_pathway.tsv` (it takes about 2,5 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9346c79-fb84-41fc-a47c-2a32c3f83722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 utilities/ko2og.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7238e-99e2-4783-812c-f8cd4fbda2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_file_scores = f'{clusters_file}.scores'\n",
    "clusters = pd.read_table(clusters_file_scores)\n",
    "\n",
    "db = 'Km'\n",
    "\n",
    "clusters = clusters[clusters['db']==db][clusters['n.mostfreq']>1]\n",
    "clusters['mostfreqfeat'] = clusters['mostfreqfeat'].apply(lambda x: x.split(' --- '))\n",
    "\n",
    "perc_thr = 50\n",
    "\n",
    "clusters['perc.ann'] = clusters['pop.ann']*100/clusters['pop']\n",
    "clusters = clusters[clusters['perc.ann']>=perc_thr]\n",
    "\n",
    "koec = pd.read_table(f\"https://rest.kegg.jp/link/enzyme/ko\", header=None, names=['ko','ec'])\n",
    "mapko = pd.read_table(f\"https://rest.kegg.jp/link/ko/path\", header=None, names=['map','ko'])\n",
    "\n",
    "maps = pd.merge(koec, mapko, how='outer')\n",
    "maps['ko'] = maps['ko'].str[3:]\n",
    "maps['map'] = maps['map'].str[5:]\n",
    "\n",
    "koog = pd.read_table(koog_file)\n",
    "\n",
    "ecmaps = pd.merge(koog, maps)\n",
    "\n",
    "clumap = clusters.explode('mostfreqfeat')[['cluster', 'pop', 'n.mostfreq', 'mostfreqfeat','ogs']]\n",
    "clumap['ogs'] = clumap['ogs'].apply(lambda x: x.split(' --- '))\n",
    "clumap = clumap.explode('ogs')\n",
    "clumap = clumap.rename(columns={'mostfreqfeat': 'map', 'ogs': 'og'})\n",
    "\n",
    "clumap = pd.merge(clumap, ecmaps, how='left')\n",
    "\n",
    "counts = []\n",
    "for c in set(clusters['cluster']):\n",
    "    for m in set(clumap[clumap['cluster']==c]['map']):\n",
    "        # aggiungere il dropna per gli EC non presenti?\n",
    "        counts.append([c, clumap[clumap['cluster']==c]['pop'].iloc[0], m, len(ecmaps[ecmaps['map']==m].drop_duplicates('ec').dropna()),\n",
    "         len(clumap[clumap['cluster']==c].drop_duplicates('ec').dropna())])\n",
    "counts = pd.DataFrame(counts)\n",
    "counts[5] = counts[4]/counts[3]\n",
    "counts.columns = ['cluster','pop','map','lenmap','lenec','ECcov']\n",
    "counts.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "counts = counts.dropna()\n",
    "\n",
    "clusters = clusters.explode(['mostfreqfeat'])\n",
    "clusters = clusters[['cluster','pop','n.mostfreq','mostfreqfeat']]\n",
    "clusters = clusters.groupby('mostfreqfeat')['n.mostfreq'].sum().reset_index()\n",
    "clusters.columns = ['map','nfreq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f358f2-ce91-48bd-90b8-d4faaba78937",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 0.8\n",
    "plt.rcParams['lines.linewidth'] = 0.8\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['xtick.labelsize'] = 6\n",
    "plt.rcParams['ytick.labelsize'] = 6\n",
    "plt.rcParams['legend.fontsize'] = 6\n",
    "\n",
    "#garbage graph\n",
    "fig = px.scatter(x=[0, 1, 2, 3, 4], y=[0, 1, 4, 9, 16])\n",
    "fig.write_image(\"random.pdf\")\n",
    "\n",
    "\n",
    "df = pd.merge(counts, clusters)\n",
    "df = df.sort_values('ECcov', ascending=False)\n",
    "keggnames = dict(keggmeta[['feature','featurename']].values)\n",
    "df['mapname'] = df['map'].apply(lambda x: keggnames.get(x))\n",
    "df = df.sort_values(['nfreq', 'ECcov'], ascending=[False,False])\n",
    "\n",
    "def customwrap(s, width=15):\n",
    "    return \"<br>\".join(textwrap.wrap(s,width=width))\n",
    "\n",
    "df['mapname'] = df['mapname'].apply(customwrap)\n",
    "df = df[df['nfreq']>=2] # default 4\n",
    "\n",
    "df = pd.merge(df.groupby('mapname')['ECcov'].sum().reset_index(),\n",
    "              df.groupby('mapname')['nfreq'].apply(list).apply(lambda x: x[0]).reset_index())\n",
    "\n",
    "fig = px.treemap(df, path=[px.Constant(\"Clusters - KEGG Meta\"), 'mapname'], values='nfreq',\n",
    "                  color='ECcov', hover_data=['ECcov'],\n",
    "                  color_continuous_scale='OrRd',\n",
    "                 width=720, height=325)\n",
    "\n",
    "percents = (100*df.ECcov / sum(df.ECcov)).tolist()\n",
    "salaries = df.ECcov.tolist()\n",
    "fig.data[0].customdata = np.column_stack([percents, salaries])\n",
    "fig.data[0].texttemplate = \"%{label}<br>nfreq: %{value}<br>ECcov: %{customdata[1]:.2f}\"\n",
    "\n",
    "fig.update_layout(margin = dict(t=5, l=5, r=5, b=5),\n",
    "                  uniformtext=dict(minsize=6))\n",
    "fig.show(renderer='notebook')\n",
    "\n",
    "if save == True:\n",
    "    fig.write_image(f'images/{clusters_file}.ECcoverage.pdf')\n",
    "    \n",
    "!rm random.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f1be0-b720-4c21-937b-6f3676677fc4",
   "metadata": {},
   "source": [
    "## Supplementary figure 7j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bb993-ce19-4bb9-9fa9-011648d6ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_file = f'{clusters_file}.scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2b700-7593-41e8-b691-e8934022fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting clusters with at least 50% of orthogroup annotated\n",
    "clusters = pd.read_table(clusters_file)\n",
    "scores = pd.read_table(scores_file)\n",
    "perc_thr = 50\n",
    "\n",
    "clusterslen = clusters.drop_duplicates('cluster').groupby('n')['cluster'].apply(len).reset_index().rename(columns={'n':'pop'})\n",
    "\n",
    "dfs = [clusterslen]\n",
    "# for d in ['P','C','F','K','Km','S']:\n",
    "for d in ['P','C','F','K','Km']:\n",
    "    scores['perc.ann'] = scores['pop.ann']*100/scores['pop']\n",
    "    scoresann = scores[scores['db']==d][scores['perc.ann']>=perc_thr]\n",
    "    clusterslendb = scoresann.groupby('pop')['cluster'].apply(len).reset_index()\n",
    "    clusterslendb = clusterslendb.rename(columns={'cluster':d})\n",
    "    dfs.append(clusterslendb)\n",
    "    \n",
    "dfsmerg = reduce(lambda left, right: \n",
    "                   pd.merge(left, right,on=['pop'], how='outer'), dfs)\n",
    "dfsmerg = dfsmerg.rename(columns={'pop':'clustersize', 'cluster':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370476ef-9256-455c-b5ff-beed0f105929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uplim = 5 # default 10\n",
    "save = True\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 0.8\n",
    "plt.rcParams['lines.linewidth'] = 0.8\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['xtick.labelsize'] = 6\n",
    "plt.rcParams['ytick.labelsize'] = 6\n",
    "plt.rcParams['legend.fontsize'] = 6\n",
    "\n",
    "dfsmerg1 = dfsmerg[dfsmerg['clustersize']<uplim]\n",
    "dfsmerg1.loc[8] = [uplim]+dfsmerg[\n",
    "    dfsmerg['clustersize']>=uplim].sum(axis=0).tolist()[1:]\n",
    "\n",
    "fig, (ax2) = plt.subplots(1, 1, figsize=(3.1,3.1), \n",
    "                          dpi=100, sharex=True)\n",
    "\n",
    "colorsfrommap = [plt.cm.jet(n)[0:3] for n in \n",
    "                 np.array(list(range(0,12)))/11]\n",
    "\n",
    "for i in range(2, uplim+1):\n",
    "\n",
    "    if i in set(dfsmerg1['clustersize']):\n",
    "        n2 = dfsmerg1[dfsmerg1['clustersize']==i]\n",
    "\n",
    "        ax2.bar(i, n2['count'].iloc[0],  0.8, label='Total', color='gainsboro')\n",
    "        # ax2.bar(i-0.3, n2['S'].iloc[0],  0.15, label='String', color=(0.2,0.5,0.2,0.8))\n",
    "        ax2.bar(i-0.3, n2['C'].iloc[0],  0.2, label='CC',        color=(0.75,0.75,0)) \n",
    "        ax2.bar(i-0.1, n2['P'].iloc[0],  0.2, label='BP',        color=(0, 0.75, 0.75))\n",
    "        ax2.bar(i+0.1, n2['K'].iloc[0],  0.2, label='KEGG',      color=(0.75, 0, 0))\n",
    "        ax2.bar(i+0.3, n2['Km'].iloc[0], 0.2, label='KEGG_Meta', color=(1, 0.65, 0))\n",
    "\n",
    "        plt.xlim(1, uplim+1)\n",
    "        ax2.set_xticks(list(range(2, uplim+1)))\n",
    "        labels = list(map(str, list(range(2, uplim+1))))\n",
    "        labels[-1] = f'>{uplim}'\n",
    "        ax2.set_xticklabels(labels)\n",
    "        if i == 2:\n",
    "            ax2.legend(loc='upper right', frameon=False)\n",
    "        \n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.xaxis.tick_bottom()\n",
    "ax2.spines[['top', 'right']].set_visible(False)\n",
    "ax2.set_xlabel('Cluster size')\n",
    "ax2.set_ylabel('# Clusters')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "\n",
    "if save == True:\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'images/{clusters_file}.distributions.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d9d26-d738-4623-abb9-bf54dc8a5338",
   "metadata": {},
   "source": [
    "## Figure 3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499fd732-fecd-490c-a100-11613bf03ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the scores for each cluster\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 0.8\n",
    "plt.rcParams['lines.linewidth'] = 0.8\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['xtick.labelsize'] = 6\n",
    "plt.rcParams['ytick.labelsize'] = 6\n",
    "plt.rcParams['legend.fontsize'] = 6\n",
    "\n",
    "save = True\n",
    "\n",
    "scores = pd.read_table(f'{clusters_file}.scores')\n",
    "# DBC score\n",
    "scores['pop.ann.perc'] = scores['pop.ann']/scores['pop']\n",
    "scores = scores[scores['pop.ann.perc']>0.5] # at least 50% annotated og in each cluster\n",
    "scores = scores[~scores['mostfreq'].astype(str).str.contains('protein binding', case=False)]\n",
    "\n",
    "ann = {'K': 'K', 'Km': 'KM', 'S': 'S', 'F': 'MF', 'P': 'BP', 'C': 'CC'}\n",
    "\n",
    "df2 = pd.concat([pd.DataFrame([[ann.get(d), len(scores[scores['db']==d][scores['score']==1].drop_duplicates('cluster')), 's=1'],\n",
    "    [ann.get(d), len(scores[scores['db']==d][scores['score']==0].drop_duplicates('cluster')), 's=0'],\n",
    "                              [ann.get(d), len(scores[scores['db']==d][(scores['score']>0)&(scores['score']<1)].drop_duplicates('cluster')), '0<s<1'],]) for d in ['K','Km','S','P','C','F']])\n",
    "df2.columns = ['type','count','slice']\n",
    "df2 = df2.reset_index(drop=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.1,3.1), dpi=100)\n",
    "for e, (colo, typ) in enumerate(zip([(0.75,0.75,0),(0,0.75,0.75),(0.75,0,0.75),(1,0.7,0.4),(1,0.7,0.4)], ['CC','BP','MF','K','KM'])):\n",
    "    ax.bar(e-0.25, df2[df2['type']==typ][df2['slice']=='s=1']['count'], width=0.25, color=colo, alpha=0.2)\n",
    "    ax.bar(e, df2[df2['type']==typ][df2['slice']=='s=0']['count'], width=0.25, color=colo, alpha=0.5)\n",
    "    ax.bar(e+0.25, df2[df2['type']==typ][df2['slice']=='0<s<1']['count'], width=0.25, color=colo, alpha=1)\n",
    "    \n",
    "ax.bar(0,0,0,color='gainsboro',label='1')\n",
    "ax.bar(0,0,0,color='gray',label='0')\n",
    "ax.bar(0,0,0,color='black',label='(0,1)')\n",
    "\n",
    "ax.set_xlabel('Database')\n",
    "ax.set_ylabel('# Clusters')\n",
    "\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "ax.set_xticklabels(['-','CC','BP','MF','KEGG','KEGG_Meta'])\n",
    "plt.legend(loc=(0.75,0.68), title='DBC score', frameon=False)\n",
    "\n",
    "ax.annotate('Gene Ontology', xy=(0.31, 1), xytext=(0.31, 1.02), xycoords='axes fraction', \n",
    "            fontsize=6, ha='center', va='bottom',color='gray',\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=7.42, lengthB=0.5',color='gray', lw=1.0))\n",
    "\n",
    "ax.annotate('KEGG PATHWAY', xy=(0.788, 1), xytext=(0.788, 1.02), xycoords='axes fraction', \n",
    "            fontsize=6, ha='center', va='bottom',color='gray',\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=4.78, lengthB=0.5',color='gray', lw=1.0))\n",
    "\n",
    "fig.savefig(f'images/{clusters_file}.annotation.scores.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cotr]",
   "language": "python",
   "name": "conda-env-cotr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
