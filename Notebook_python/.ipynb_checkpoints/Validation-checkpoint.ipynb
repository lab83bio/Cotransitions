{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5e85ff-7327-4d10-83bd-9c871ba7a4f6",
   "metadata": {},
   "source": [
    "`To run the same project analysis, run cells 1, 6, 7`\n",
    "\n",
    "`To generate raw files or run a new analysis, change the 'filebase' variable and run all cells`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ee78c8-8137-410c-ae97-9dda688fdbcc",
   "metadata": {},
   "source": [
    "# Import and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d677c9-397f-460e-a6dd-6b0387b507fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "# import io\n",
    "# import contextlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7288be4f-ddff-4542-b7f5-8c7ef17c68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4531685c-95c2-4d9e-ae38-799e8339d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_file = 'yeastw_opt.csv'\n",
    "validation_file_out = f'{validation_file}.transitions'\n",
    "\n",
    "typ = 'yeast'\n",
    "scoretag = 'logp' # other choices: ['logp', 'logp.score>0', 'logp.score>0p1', '.scores']\n",
    "tags = ['R1', 'ncbi.LL','ncbi.LR','ncbi.NL',\n",
    "        'tree.LR','tree.LL','tree.NL']\n",
    "\n",
    "outblast = 'ye288ye1573'\n",
    "outmapped = f'{outblast}.mapped'\n",
    "\n",
    "odbxref_file = 'odb10v1_gene_xrefs.tab.gz'\n",
    "odbgenes_file = 'odb10v1_OG2genes.tab.gz'\n",
    "\n",
    "ye1573_file = 'Saccharomyces_cerevisiae_yjm1573_gca_000978255.Sc_YJM1573_v1.pep.all.fa'\n",
    "ye288_file = 'Saccharomyces_cerevisiae.R64-1-1.pep.all.fa'\n",
    "ye288_xref_file = 'Saccharomyces_cerevisiae.R64-1-1.107.uniprot.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e85f32-3879-4397-b5c5-316128bc2429",
   "metadata": {},
   "source": [
    "Change the `filebase` variable into the next cell to indicate the transitions files to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33d11a-b915-4fe4-81ba-0478454dc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filebase = '../../../definitivo/validation/HogProf/Eukaryota.test'\n",
    "# file example: Eukaryota.test.ncbi.NL.csv.num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b18377-61c5-4052-85ef-c3f360039694",
   "metadata": {},
   "source": [
    "# Raw files download\n",
    "- HogProf yeast analysis dataset\n",
    "- OrthoDB orthogroup to genes\n",
    "- OrthoDB gene xrefs\n",
    "- Sc R64 FASTA\n",
    "- Sc YJM1573 FASTA\n",
    "- Sc R64 Uniprot to Ensembl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944479aa-5055-48b0-bb4b-d042a2c1e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!curl -O https://raw.githubusercontent.com/DessimozLab/HogProf/master/pyprofiler/notebooks/validation_set/TaSuppData/yeastw_opt.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db22b07-1864-4cc9-aec3-e9452cdbeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fastas and xref file download\n",
    "!curl -O http://ftp.ensembl.org/pub/release-106/fasta/saccharomyces_cerevisiae/pep/Saccharomyces_cerevisiae.R64-1-1.pep.all.fa.gz\n",
    "!curl -O http://ftp.ensemblgenomes.org/pub/fungi/release-53/fasta/fungi_ascomycota2_collection/saccharomyces_cerevisiae_yjm1573_gca_000978255/pep/Saccharomyces_cerevisiae_yjm1573_gca_000978255.Sc_YJM1573_v1.pep.all.fa.gz\n",
    "!curl -O http://ftp.ensembl.org/pub/current_tsv/saccharomyces_cerevisiae/Saccharomyces_cerevisiae.R64-1-1.107.uniprot.tsv.gz\n",
    "\n",
    "!gunzip {ye288_file}.gz\n",
    "!gunzip {ye1573_file}.gz\n",
    "!gunzip {ye288_xref_file}.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4d96c-4af7-4b8c-a3af-22f1ec131de2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if f'{odbxref_file}.YJM1573' not in os.listdir():\n",
    "    \n",
    "    og2genes = pd.read_table(f'https://v101.orthodb.org/download/{odbxref_file}', header=None)\n",
    "    genexref = pd.read_table(f'https://v101.orthodb.org/download/{odbgenes_file}', header=None)\n",
    "\n",
    "    og2genes[og2genes[0].str.contains('1294385_1')].to_csv(f'{odbxref_file}.YJM1573', sep='\\t', index=None, header=None)\n",
    "    genexref[genexref[1].str.contains('1294385_1')].to_csv(f'{odbgenes_file}.YJM1573', sep='\\t', index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb4d37f-b314-4b84-ac03-b98a93b447f1",
   "metadata": {},
   "source": [
    "# BLAST\n",
    "- `Saccharomyces_cerevisiae.R64-1-1` (Uniprot)\n",
    "- `Saccharomyces_cerevisiae_yjm1573` (OrthoDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab880a-d50a-472f-aa17-4ce3f7776bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# given the different strain used by orthodb, uniprot and ensembl\n",
    "# mapping the ogs through a BLAST\n",
    "\n",
    "if outblast not in os.listdir():\n",
    "\n",
    "    !makeblastdb -in {ye1573_file} -dbtype 'prot'\n",
    "    !blastp -query {ye288_file} -db {ye1573_file} -out {outblast} -outfmt=6 -max_target_seqs 6 -num_threads 32\n",
    "\n",
    "blast = pd.read_table(outblast, header=None)[[0,1,2,10,11]]\n",
    "blast.columns = ['gene1','gene2','percid','eval','bitscore']\n",
    "\n",
    "if outmapped not in os.listdir():\n",
    "\n",
    "    # bitscore priority with the same og ids and uniprot ids\n",
    "    # allowed multiple ogs if associated to different uniprot ids\n",
    "\n",
    "    odbxref = pd.read_table(odbxref_file+'.YJM1573', header=None)\n",
    "    odbxref[1] = odbxref[1].apply(lambda x: x.split('.')[0])\n",
    "    odbxref = odbxref[odbxref[2]=='NCBIproteinAcc']\n",
    "    odbxrefs = dict(odbxref[[1,0]].values)\n",
    "\n",
    "    odbgene = pd.read_table(odbgenes_file+'.YJM1573', header=None)\n",
    "    odbgene = odbgene[odbgene[0].str.endswith('at2759')]\n",
    "\n",
    "    blast = pd.merge(blast, odbxref[[0,1]].rename(\n",
    "        columns={1: 'gene2', 0: 'odb2'}))\n",
    "    blast = pd.merge(blast, odbgene.rename(\n",
    "        columns={0: 'og2', 1: 'odb2'}))\n",
    "    xref = pd.read_table(ye288_xref_file)\n",
    "    blast = pd.merge(blast, xref[['xref','gene_stable_id']].rename(\n",
    "        columns={'xref': 'uni1', 'gene_stable_id': 'gene1'}))\n",
    "\n",
    "    yeast = pd.read_table(validation_file, sep=',')\n",
    "    alluni = set(yeast['ProA'].tolist()+yeast['proB'].tolist())\n",
    "    blast = blast[blast['uni1'].isin(alluni)]\n",
    "\n",
    "    blast2 = blast[blast['eval']<=1e-2][blast['percid']>=70]\n",
    "    b1 = blast2.sort_values('bitscore', ascending=False\n",
    "                           ).drop_duplicates('uni1')\n",
    "\n",
    "    yeast = pd.read_table(validation_file, sep=',').iloc[:,3:]\n",
    "    yeast1 = pd.merge(yeast, b1[['uni1','og2']], \n",
    "                      left_on='ProA', right_on='uni1')\n",
    "    yeast1 = pd.merge(yeast1, b1[['uni1','og2']], \n",
    "                      left_on='proB', right_on='uni1')\n",
    "    yeast1 = yeast1.drop(['uni1_x','uni1_y'], axis=1\n",
    "                        ).rename(columns={\n",
    "        'og2_x': 'og1', 'og2_y': 'og2'})\n",
    "    yeast1 = yeast1.drop_duplicates()\n",
    "    yeast1.to_csv(outmapped, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f6f38-05d3-4438-8f68-13fe87ce9d88",
   "metadata": {},
   "source": [
    "# Transitions and pvalue\n",
    "- `get_transitions_validation.py`\n",
    "- `procedure_Orthodb_Fisher.r`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9a377-eb81-45fd-a35a-1f4df89c921e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# filebase = '../../../definitivo/validation/HogProf/Eukaryota.test'\n",
    "def gettrans(tag):\n",
    "\n",
    "    csv1, csv2 = f'{filebase}.{tag}.csv.num', outmapped\n",
    "\n",
    "    # with contextlib.redirect_stdout(io.StringIO()):\n",
    "    !python3 get_transitions_validation.py {csv1} {csv2} | procedure_Orthodb_Fisher.r -p 1 -pa 1 - > {os.path.basename(csv1)}.{typ}\n",
    "    !python3 get_transitions_validation.py {csv1} {csv2} -c | procedure_Orthodb_Fisher.r -p 1 -pa 1 - > {os.path.basename(csv1)}.{typ}.C\n",
    "\n",
    "# if not f'Eukaryota.test.{tags[0]}.csv.num.{typ}' in os.listdir():\n",
    "Pool(9).map(gettrans, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb307b0d-a63f-4456-b8e9-e0839ac87130",
   "metadata": {},
   "source": [
    "# Cotr to HogProf mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26804076-a9ec-46cd-9a97-544af3bdf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def addnormp(yeast, tag, scoretag, penalized=True):\n",
    "    ''' return a -log10pval or score based ranking dataframe given a \n",
    "    method tag and an input file containing pairs to study '''\n",
    "    \n",
    "    transitions_file = f'{filebase}.{tag}.csv.num.{typ}'\n",
    "    if not penalized:\n",
    "        transitions_file = f'{filebase}.{tag}.csv.num.{typ}.C'\n",
    "    transitions = pd.read_table(transitions_file)\n",
    "    transitions['ogs'] = transitions.apply(\n",
    "        lambda x: '|'.join(sorted([x['G1'],x['G2']])), axis=1)\n",
    "\n",
    "    transitions['normp'] = transitions['p'].apply(lambda x: -np.log10(x))\n",
    "    transitions.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    transitions['k_score'] = transitions['k_score'].astype(float)\n",
    "\n",
    "    ## positive scores\n",
    "    if scoretag == 'logp.scores>0':\n",
    "        transitions = transitions[transitions['k_score']>=0]\n",
    "    \n",
    "    ## negative scores --> pval == 1\n",
    "    if scoretag == 'logp.scores>0p1':\n",
    "        transitions['normp'] = transitions.apply(\n",
    "            lambda x: x['normp'] if x['k_score']>=0 else 0)\n",
    "        \n",
    "    scores = dict(transitions[['ogs','normp']].values)\n",
    "\n",
    "    ## only scores\n",
    "    if scoretag == '.scores':\n",
    "        transitions['k_score'] = transitions['k_score'].astype(float)\n",
    "        scores = dict(transitions[['ogs','k_score']].values)\n",
    "\n",
    "    yeast['ogs'] = yeast.apply(lambda x: '|'.join(\n",
    "        sorted([x['og1'],x['og2']])), axis=1)\n",
    "    yeast['normp'] = yeast['ogs'].apply(lambda x: scores.get(x))\n",
    "    yeast = yeast.rename(columns={'normp': tag})\n",
    "\n",
    "    return yeast\n",
    "\n",
    "yeast = pd.read_table(outmapped)\n",
    "\n",
    "yeastmapped = pd.DataFrame([addnormp(\n",
    "    yeast, tag, scoretag, penalized=True).iloc[:,-1] \n",
    "                            for tag in tags]).T\n",
    "yeastmapped = pd.concat([yeast, yeastmapped], axis=1)\n",
    "yeastmapped.to_csv(f'{validation_file_out}.{scoretag}',\n",
    "                   index=None, sep='\\t')\n",
    "\n",
    "yeastmapped = pd.DataFrame([addnormp(\n",
    "    yeast, tag, scoretag, penalized=False).iloc[:,-1] \n",
    "                            for tag in tags]).T\n",
    "yeastmapped = pd.concat([yeast, yeastmapped], axis=1)\n",
    "yeastmapped.to_csv(f'{validation_file_out}.{scoretag}.C', \n",
    "                   index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c83a9e-18eb-4fda-b6f9-20d4c7bd57a4",
   "metadata": {},
   "source": [
    "# Cotr AUC calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d3cdf1-828e-45e0-8e9e-e0dc6b31c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def returnaucscores(outyeast_file, p, tags, penalizedonly=False):\n",
    "    ''' calculate roc_auc for each scoring methods '''\n",
    "    \n",
    "    df = pd.read_table(f'{outyeast_file}')\n",
    "    df = df[df['og1']!=df['og2']]\n",
    "    df['id'] = df.apply(\n",
    "        lambda x: '|'.join(sorted([x['ProA'],\n",
    "                                   x['proB']])), axis=1)\n",
    "\n",
    "    if not penalizedonly:\n",
    "        \n",
    "        df2 = pd.read_table(f'{outyeast_file}.C')\n",
    "        df2 = df2[df2['og1']!=df2['og2']]\n",
    "        df2['id'] = df2.apply(\n",
    "            lambda x: '|'.join(sorted([x['ProA'],\n",
    "                                       x['proB']])), axis=1)\n",
    "\n",
    "    results = []\n",
    "    for score in tags:\n",
    "\n",
    "        sub = df[[score,'truth']].dropna()\n",
    "        \n",
    "        # for k_score type only:\n",
    "        sub[score] = sub[score].astype(float)\n",
    "        sub = sub.dropna()\n",
    "            \n",
    "        sub = sub.sort_values(score, axis=0, ascending=True)\n",
    "        y_test = sub.truth\n",
    "        y_pred = (sub[score]-sub[score].min()\n",
    "                 )/(sub[score].max()-sub[score].min()) \n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        if not penalizedonly:\n",
    "            \n",
    "            sub = df2[[score,'truth']].dropna()    \n",
    "            \n",
    "            # for k_score type only:\n",
    "            sub[score] = sub[score].astype(float)\n",
    "            sub = sub.dropna()\n",
    "            \n",
    "            sub = sub.sort_values(score, axis=0, ascending=True)\n",
    "            y_test = sub.truth\n",
    "            y_pred = (sub[score]-sub[score].min()\n",
    "                     )/(sub[score].max()-sub[score].min()) \n",
    "            fpr2, tpr2, _ = roc_curve(y_test, y_pred)\n",
    "            roc_auc2 = auc(fpr2, tpr2)\n",
    "            results.append([score, roc_auc, fpr, tpr, \n",
    "                            roc_auc2, fpr2, tpr2])\n",
    "\n",
    "        else:\n",
    "            results.append([score, roc_auc, fpr, tpr])\n",
    "\n",
    "    if not penalizedonly:\n",
    "        results = pd.DataFrame(results, columns=[\n",
    "            'method','rocauc','fpr','tpr',\n",
    "            'rocaucp','fprp','tprp'])\n",
    "    else:\n",
    "        results = pd.DataFrame(results, columns=[\n",
    "            'method','rocauc','fpr','tpr'])\n",
    "    results = results.sort_values('rocauc', ascending=False)\n",
    "    \n",
    "    return df, df2, results\n",
    "\n",
    "penalizeddf, nonpenalizeddf, respenalized = returnaucscores(\n",
    "    f'{validation_file_out}.{scoretag}', 4, \n",
    "    tags, penalizedonly=False)\n",
    "\n",
    "# penalizeddf.to_csv(f'{validation_file_out}.{scoretag}.raw', sep='\\t', index=None)\n",
    "# nonpenalizeddf.to_csv(f'{validation_file_out}.{scoretag}.C.raw', sep='\\t', index=None)\n",
    "# respenalized.to_csv(f'{validation_file_out}.{scoretag}.results', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdd3a90-40fa-49d1-90f2-5b47bdba7118",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9baacba-3855-4fe4-9f2e-4a07be3e3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(f'{validation_file_out}.{scoretag}')\n",
    "df = df[df['og1']!=df['og2']]\n",
    "df['id'] = df.apply(lambda x: '|'.join(\n",
    "    sorted([x['ProA'],x['proB']])), axis=1)\n",
    "\n",
    "p = 4\n",
    "\n",
    "lens = []\n",
    "for tag in tags:\n",
    "    \n",
    "        sign1 = len(df[df[tag]>=p][df['truth']==1]\n",
    "                   )/len(df[df[tag]>=p])\n",
    "        sign2 = len(df[df[tag]<p][df['truth']==1]\n",
    "                   )/len(df[df[tag]<p])\n",
    "\n",
    "        sign3 = len(df[df[tag]>=p][df['truth']==0]\n",
    "                   )/len(df[df[tag]>=p])\n",
    "        sign4 = len(df[df[tag]<p][df['truth']==0]\n",
    "                   )/len(df[df[tag]<p])\n",
    "\n",
    "        lens.append([\n",
    "            tag, sign1, sign2, len(df[df[tag]>=p][df['truth']==1]), \n",
    "            len(df[df[tag]<p][df['truth']==1]),\n",
    "            sign3, sign4, len(df[df[tag]>=p][df['truth']==0]), \n",
    "            len(df[df[tag]<p][df['truth']==0]),\n",
    "                    ])\n",
    "\n",
    "lens = pd.DataFrame(lens, columns=['method','perc_sign', 'perc_nonsign', \n",
    "                                   'len_sign', 'len_nonsign','perc_sign0',\n",
    "                                   'perc_nonsign0','len_sign0','len_nonsign0'])\n",
    "lens.to_csv(f'{validation_file_out}.{scoretag}.percentage', \n",
    "            sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0b662-3501-4219-9450-afd274829599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a set of parameters for project uniformity\n",
    "plt.rcParams['axes.linewidth'] = 0.8\n",
    "plt.rcParams['lines.linewidth'] = 0.8\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['xtick.labelsize'] = 6\n",
    "plt.rcParams['ytick.labelsize'] = 6\n",
    "plt.rcParams['legend.fontsize'] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f7253-8e30-45b9-bd66-561e2db6af19",
   "metadata": {},
   "source": [
    "## Penalized vs non penalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec1e486-e621-41f8-adf8-4d9aef87dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = respenalized[respenalized['method'].isin(['tree.LR'])]\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(3.1,3.1), dpi=100)\n",
    "ax1.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "\n",
    "for i, row in enumerate(df.values.tolist()):\n",
    "    ax1.plot(row[2], row[3], label=str(\n",
    "        row[0]+f' {round(row[1], 3)}'), linewidth=1, alpha=1)\n",
    "    ax1.plot(row[5], row[6], label=str(\n",
    "        row[0]+f'.np {str(round(row[4], 3))}'), linewidth=1, alpha=1)\n",
    "    \n",
    "ax1.set_xlabel('False positive rate')\n",
    "ax1.set_ylabel('True positive rate')\n",
    "\n",
    "ax1.spines[['right','top']].set_visible(False)\n",
    "ax1.set_title(f'{typ} PPI prediction ROC curve')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.savefig(f'{validation_file_out}.{scoretag}.results.pen.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59e8511-c8cb-4699-b7cc-200ebb976050",
   "metadata": {},
   "source": [
    "## Tree vs NCBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ec046-6030-4d98-846e-402fd38d60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = respenalized[respenalized['method'].isin([\n",
    "    'tree.LR','tree.NL','tree.LL',\n",
    "    'ncbi.LR','ncbi.LL','ncbi.NL','R1'])]\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(3.1,3.1), dpi=100)\n",
    "ax1.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "\n",
    "for i, row in enumerate(df.values.tolist()):\n",
    "    ax1.plot(row[2], row[3], label=str(\n",
    "        row[0]+f' {round(row[1], 3)}'), linewidth=1, alpha=1)\n",
    "        \n",
    "ax1.set_xlabel('False positive rate')\n",
    "ax1.set_ylabel('True positive rate')\n",
    "\n",
    "ax1.spines[['right','top']].set_visible(False)\n",
    "ax1.set_title(f'{typ} PPI prediction ROC curve')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.savefig(f'{validation_file_out}.{scoretag}.results.treencbi.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1bb529-20d2-4f44-bfba-1d5687ceabb3",
   "metadata": {},
   "source": [
    "## Tree LR, Jaccard hash, EPT, Binary Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56876d15-81d1-42fc-a6a0-2412747d55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(f'{validation_file_out}.{scoretag}')\n",
    "df = df[df['og1']!=df['og2']]\n",
    "\n",
    "results = []\n",
    "for score in ['jaccard_hash','Bin_Ps','EPT_score','tree.LR']:\n",
    "\n",
    "    sub = df[[score,'truth']].dropna()       \n",
    "    sub = sub.sort_values(score, axis=0, ascending=True)\n",
    "    y_test = sub.truth\n",
    "    y_pred = (sub[score]-sub[score].min()\n",
    "             )/(sub[score].max()-sub[score].min()) \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    results.append([score, roc_auc, fpr, tpr])\n",
    "results = pd.DataFrame(results)\n",
    "results = results.sort_values(0, ascending=False)\n",
    "results.to_csv(f'{validation_file_out}.{scoretag}.results.LRvJaccard', \n",
    "               sep='\\t', index=None)\n",
    "\n",
    "df = results\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(3.1,3.1), dpi=100)\n",
    "ax1.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "\n",
    "for i, row in enumerate(df.values.tolist()):\n",
    "    ax1.plot(row[2], row[3], label=\n",
    "             row[0]+f' {round(row[1], 3)}', linewidth=1, alpha=1)\n",
    "        \n",
    "ax1.set_xlabel('False positive rate')\n",
    "ax1.set_ylabel('True positive rate')\n",
    "\n",
    "ax1.spines[['right','top']].set_visible(False)\n",
    "ax1.set_title(f'{typ} PPI prediction ROC curve')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.savefig(f'{validation_file_out}.{scoretag}.results.LRvJaccard.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
